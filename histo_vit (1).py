# -*- coding: utf-8 -*-
"""histo_vit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tq4Z78cxNchthydtwk1fTZlJ7NtgLFL6
"""

!unzip /content/drive/MyDrive/histodataset860.zip

#code to login google drive
from google.colab import drive
drive.mount('/content/drive')

#to visulize the excel

import pandas as pd
import matplotlib.pyplot as plt

file_path = "/content/CA-125-KAGGLE.xlsx"
df = pd.read_excel(file_path)
column_name = "CA125"
df[column_name] = df[column_name].astype(str).str.replace(">", "").astype(float)

plt.figure(figsize=(15, 5))
plt.bar(df.index, df[column_name], color='b')
plt.xlabel("Subjects")
plt.ylabel("CA-125 Levels")
plt.title("CA-125 Levels for All Subjects")
plt.show()

#visualize datasets and labels

import os
import matplotlib.pyplot as plt
from PIL import Image
import random

train_path = "/content/histodataset860"
labels = ["EC_images", "CC_images", "HGSC_images", "LGSC_images", "MC_images"]

num_images_per_label = 10

fig, axes = plt.subplots(len(labels), num_images_per_label, figsize=(15, 10))
fig.subplots_adjust(wspace=0, hspace=0)

for i, label in enumerate(labels):
    label_path = os.path.join(train_path, label)
    images = os.listdir(label_path)

    selected_images = random.sample(images, min(num_images_per_label, len(images)))

    for j, img_name in enumerate(selected_images):
        img_path = os.path.join(label_path, img_name)
        img = Image.open(img_path)

        axes[i, j].imshow(img)
        axes[i, j].axis("off")
        if j == 0:
            axes[i, j].set_title(label, fontsize=12, fontweight="bold", loc='left')

plt.show()

#overall visualization

import pandas as pd
import matplotlib.pyplot as plt

# Function to classify CA-125 levels based on your table
def classify_ca125(ca125_value):
    if ca125_value < 35:
        return "MC (Mucinous Carcinoma)", "Normal or Mild"
    elif 35 <= ca125_value <= 150:
        return "EC (Endometrioid Carcinoma)", "Mild to Moderate"
    elif ca125_value <= 300:
        return "CC (Clear Cell Carcinoma) or LGSC", "Mild to Moderate"
    else:  # >300
        return "HGSC (High-Grade Serous Carcinoma)", "High to Extremely High"

# Read and process the Excel file
file_path = "/content/CA-125-KAGGLE.xlsx"
df = pd.read_excel(file_path)
column_name = "CA125"
df[column_name] = df[column_name].astype(str).str.replace(">", "").astype(float)

# Make predictions for each value
predictions = []
for value in df[column_name]:
    cancer_type, classification = classify_ca125(value)
    predictions.append({
        "CA-125 Level": value,
        "Predicted Cancer Type": cancer_type,
        "Classification": classification
    })

# Convert predictions to DataFrame
results_df = pd.DataFrame(predictions)

# Display results
print("Prediction Results:")
print(results_df)
import matplotlib.cm as cm
norm = plt.Normalize(results_df['CA-125 Level'].min(), results_df['CA-125 Level'].max())
colors = cm.viridis(range(len(results_df['Predicted Cancer Type'].unique())))

# Visualize the data with predictions
plt.figure(figsize=(15, 5))
bars = plt.bar(df.index, df[column_name], color = colors)
plt.xlabel("Subjects")
plt.ylabel("CA-125 Levels")
plt.title("CA-125 Levels with Predicted Cancer Types")

# Add some prediction labels to the plot (showing every 5th bar for clarity)
for i, bar in enumerate(bars):
    if i % 5 == 0:  # Show every 5th label to avoid clutter
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{results_df["Predicted Cancer Type"][i]}\n{height}',
                ha='center', va='bottom', rotation=45)

plt.tight_layout()
plt.show()

# Basic statistics
print("\nBasic Statistics:")
print(results_df["Predicted Cancer Type"].value_counts())

cancer_types = results_df['Predicted Cancer Type'].unique()
colors = cm.viridis(range(len(cancer_types)))
color_mapping = {cancer_type: color for cancer_type, color in zip(cancer_types, colors)}
results_df['Color'] = results_df['Predicted Cancer Type'].map(color_mapping)
plt.scatter(x=results_df.index, y=results_df["CA-125 Level"], c=results_df["Color"])
plt.yscale('log')
plt.show()

results_df

import time
timestamp = time.strftime("%Y%m%d-%H%M%S")
output_filename = f"results_{timestamp}.csv"
results_df.to_csv(output_filename, mode='a', header=not os.path.exists(output_filename), index=False)
print(f"Results appended to {output_filename}")

import os
train_path = "/content/histodataset860"
labels = ["EC_images", "CC_images", "HGSC_images", "LGSC_images", "MC_images"]

for label in labels:
  label_path = os.path.join(train_path, label)
  num_images = len(os.listdir(label_path))
  print(f"Number of images in {label}: {num_images}")

#actual traning begins here


import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import ViTForImageClassification, ViTFeatureExtractor
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from google.colab import drive

torch.manual_seed(42)
np.random.seed(42)

labels = ["MC", "EC", "HGSC", "LGSC", "CC"]
label_map = {"MC": 0, "EC": 1, "HGSC": 2, "LGSC": 3, "CC": 4}
print("Label Positions: MC = 0, EC = 1, HGSC = 2, LGSC = 3, CC = 4")

def pseudo_label_ca125(ca125_data):
    cleaned_ca125 = []
    for val in ca125_data:
        if isinstance(val, str):
            val = val.strip()
            if val.startswith('>'):
                val = val.replace('>', '').strip()
            try:
                cleaned_val = float(val)
            except ValueError:
                print(f"Warning: Could not convert '{val}' to float, defaulting to 5000")
                cleaned_val = 5000.0
        else:
            cleaned_val = float(val)
        cleaned_ca125.append(cleaned_val)

    ca125 = pd.Series(cleaned_ca125).replace(5000, 5000.0)
    sorted_ca125 = ca125.sort_values()
    n_per_label = 80

    if len(sorted_ca125) < 5 * n_per_label:
        print(f"Warning: Only {len(sorted_ca125)} CA-125 values, padding with median")
        padding = np.full(5 * n_per_label - len(sorted_ca125), sorted_ca125.median())
        sorted_ca125 = pd.concat([sorted_ca125, pd.Series(padding)])
    elif len(sorted_ca125) > 5 * n_per_label:
        print(f"Warning: Truncating {len(sorted_ca125)} CA-125 values to {5 * n_per_label}")
        sorted_ca125 = sorted_ca125[:5 * n_per_label]

    pseudo_labels = {
        "MC": sorted_ca125[:n_per_label].values,
        "EC": sorted_ca125[n_per_label:2*n_per_label].values,
        "HGSC": sorted_ca125[2*n_per_label:3*n_per_label].values,
        "LGSC": sorted_ca125[3*n_per_label:4*n_per_label].values,
        "CC": sorted_ca125[4*n_per_label:5*n_per_label].values
    }
    return pseudo_labels

try:
    df = pd.read_excel("/content/CA-125-KAGGLE.xlsx", engine='openpyxl')
    print("First few rows of CA-125 data:")
    print(df["CA125"].head())
    pseudo_ca125 = pseudo_label_ca125(df["CA125"])
except Exception as e:
    print(f"Error loading CA-125 data: {e}")
    raise

class HistopathDataset(Dataset):
    def __init__(self, image_paths, cancer_types, ca125_values, feature_extractor):
        self.image_paths = image_paths
        self.cancer_types = cancer_types
        self.ca125 = ca125_values
        self.feature_extractor = feature_extractor

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        try:
            img = Image.open(self.image_paths[idx]).convert("RGB")
            inputs = self.feature_extractor(img, return_tensors="pt")
            return (inputs["pixel_values"].squeeze(),
                    torch.tensor(self.cancer_types[idx], dtype=torch.long),
                    torch.tensor(self.ca125[idx], dtype=torch.float))
        except Exception as e:
            print(f"Error loading image {self.image_paths[idx]}: {e}")
            return None

class MultiTaskViT(nn.Module):
    def __init__(self, base_model):
        super().__init__()
        self.vit = base_model
        self.class_head = nn.Linear(768, 5)  # 5 outputs: 0=MC, 1=EC, 2=HGSC, 3=LGSC, 4=CC
        self.reg_head = nn.Linear(768, 1)    # CA-125 regression

    def forward(self, pixel_values):
        outputs = self.vit(pixel_values=pixel_values, output_hidden_states=True)
        cls_token = outputs.hidden_states[-1][:, 0, :]
        class_logits = self.class_head(cls_token)
        reg_output = self.reg_head(cls_token)
        return class_logits, reg_output

# Early Stopping Class
class EarlyStopping:
    def __init__(self, patience=5, delta=0):
        self.patience = patience
        self.delta = delta
        self.best_loss = float('inf')
        self.counter = 0
        self.early_stop = False

    def __call__(self, val_loss, model):
        if math.isnan(val_loss):
            print("NaN loss detected, saving current model and stopping early")
            torch.save(model.state_dict(), '/content/drive/MyDrive/best_model.pt')
            print("Saved best_model.pt due to NaN loss")
            self.early_stop = True
            return
        if val_loss < self.best_loss - self.delta:
            self.best_loss = val_loss
            self.counter = 0
            print(f"Saving best model with val_loss: {val_loss:.4f}")
            torch.save(model.state_dict(), '/content/drive/MyDrive/best_model.pt')
            print("Saved best_model.pt successfully")
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True

# Data Preparation
base_path = "/content/histodataset860"   #chnage your path here
image_paths, cancer_types, ca125_values = [], [], []
for label in labels:
    folder = os.path.join(base_path, f"{label}_images")
    try:
        imgs = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.jpg', '.png'))]
        n_images = len(imgs[:80])
        image_paths.extend(imgs[:80])
        cancer_types.extend([label_map[label]] * n_images)
        ca125_vals = pseudo_ca125[label]
        if len(ca125_vals) != n_images:
            print(f"Warning: {label} has {n_images} images but {len(ca125_vals)} CA-125 values, adjusting")
            if len(ca125_vals) < n_images:
                ca125_vals = np.pad(ca125_vals, (0, n_images - len(ca125_vals)), mode='edge')
            else:
                ca125_vals = ca125_vals[:n_images]
        ca125_values.extend(ca125_vals)
    except Exception as e:
        print(f"Error accessing {folder}: {e}")

print(f"Length of image_paths: {len(image_paths)}")
print(f"Length of cancer_types: {len(cancer_types)}")
print(f"Length of ca125_values: {len(ca125_values)}")

# Split into train/test
train_paths, test_paths, train_types, test_types, train_ca125, test_ca125 = train_test_split(
    image_paths, cancer_types, ca125_values, test_size=0.2, stratify=cancer_types, random_state=42
)

# Load ViT feature extractor and datasets
feature_extractor = ViTFeatureExtractor.from_pretrained("google/vit-base-patch16-224")
train_dataset = HistopathDataset(train_paths, train_types, train_ca125, feature_extractor)
test_dataset = HistopathDataset(test_paths, test_types, test_ca125, feature_extractor)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)

# Model Setup
base_model = ViTForImageClassification.from_pretrained("google/vit-base-patch16-224")
model = MultiTaskViT(base_model.vit)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Save initial model state as a fallback
print("Saving initial model state as best_model.pt")
torch.save(model.state_dict(), '/content/drive/MyDrive/best_model.pt')

optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
class_loss_fn = nn.CrossEntropyLoss()
reg_loss_fn = nn.MSELoss()
early_stopping = EarlyStopping(patience=10)

train_losses, val_losses = [], []
epochs = 50

# Add lists to store metrics
val_accuracies, val_precisions, val_recalls, val_f1s = [], [], [], []

# Define early stopping parameters
early_stopping_patience = 5  # Number of epochs to wait for improvement
early_stopping_min_delta = 0.001  # Minimum change to qualify as improvement
best_val_loss = float('inf')
patience_counter = 0

for epoch in range(epochs):
    model.train()
    train_loss = 0
    valid_batches = 0
    for batch in train_loader:
        if batch is None: continue
        images, cancer_types, ca125 = batch
        images, cancer_types, ca125 = images.to(device), cancer_types.to(device), ca125.to(device)

        optimizer.zero_grad()
        class_logits, reg_output = model(images)

        class_loss = class_loss_fn(class_logits, cancer_types)
        reg_loss = reg_loss_fn(reg_output.squeeze(), torch.log(ca125))
        loss = class_loss + reg_loss

        if torch.isnan(loss):
            #print(f"NaN loss in training: class_loss={class_loss.item()}, reg_loss={reg_loss.item()}")
            continue

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        train_loss += loss.item()
        valid_batches += 1

    train_loss = train_loss / max(valid_batches, 1)
    train_losses.append(train_loss)

    # Validation phase with metrics
    model.eval()
    val_loss = 0
    valid_batches = 0
    all_preds, all_labels = [], []

    with torch.no_grad():
        for batch in test_loader:
            if batch is None: continue
            images, cancer_types, ca125 = batch
            images, cancer_types, ca125 = images.to(device), cancer_types.to(device), ca125.to(device)
            class_logits, reg_output = model(images)
            class_loss = class_loss_fn(class_logits, cancer_types)
            reg_loss = reg_loss_fn(reg_output.squeeze(), torch.log(ca125))
            val_loss += (class_loss + reg_loss).item()
            valid_batches += 1

            preds = torch.argmax(class_logits, dim=1)
            all_preds.append(preds.cpu())
            all_labels.append(cancer_types.cpu())

    val_loss = val_loss / max(valid_batches, 1)
    val_losses.append(val_loss)

    # Calculate metrics
    all_preds = torch.cat(all_preds)
    all_labels = torch.cat(all_labels)

    # Import metrics
    from sklearn.metrics import precision_score, recall_score, f1_score

    # Calculate metrics
    accuracy = (all_preds == all_labels).float().mean().item()
    precision = precision_score(all_labels.numpy(), all_preds.numpy(), average='weighted', zero_division=0)
    recall = recall_score(all_labels.numpy(), all_preds.numpy(), average='weighted', zero_division=0)
    f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average='weighted', zero_division=0)

    # Append metrics
    val_accuracies.append(accuracy)
    val_precisions.append(precision)
    val_recalls.append(recall)
    val_f1s.append(f1)

    # Print results with F1 score
    print(f"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, "
          f"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}")

    # Early stopping logic
    if val_loss < best_val_loss - early_stopping_min_delta:
        best_val_loss = val_loss
        patience_counter = 0

        # Save best model
        torch.save(model.state_dict(), '/content/drive/MyDrive/best_model.pt')
    else:
        patience_counter += 1
        if patience_counter >= early_stopping_patience:
            print(f"Early stopping triggered after {epoch+1} epochs")
            break


try:
    model.load_state_dict(torch.load('/content/drive/MyDrive/best_model.pt'))
    print("Loaded best_model.pt successfully")
except FileNotFoundError:
    print("best_model.pt not found, but initial state was saved earlier")

# Evaluation
model.eval()
all_preds, all_labels, all_ca125_true, all_ca125_pred = [], [], [], []
with torch.no_grad():
    for batch in test_loader:
        if batch is None: continue
        images, cancer_types, ca125 = batch
        images, cancer_types, ca125 = images.to(device), cancer_types.to(device), ca125.to(device)
        class_logits, reg_output = model(images)
        preds = torch.argmax(class_logits, dim=1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(cancer_types.cpu().numpy())
        all_ca125_true.extend(ca125.cpu().numpy())
        all_ca125_pred.extend(np.exp(reg_output.squeeze().cpu().numpy()))

# prompt: plot accuracy graph  ROC curve

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
import numpy as np

# Assuming 'all_labels' and 'all_preds' are already defined from your previous code

# Binarize the output
y_true = label_binarize(all_labels, classes=np.unique(all_labels))
y_score = np.zeros_like(y_true)

# Assuming all_preds is a list of class indices, transform them to probabilities
# In a real scenario, use proper probability outputs of your classifier
for i, pred in enumerate(all_preds):
  y_score[i, pred] = 1

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
n_classes = y_true.shape[1]

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_true.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

# Plot ROC curves for each class
plt.figure(figsize=(10, 8))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], label=f'Class {i} (area = {roc_auc[i]:.2f})')

plt.plot(fpr["micro"], tpr["micro"], label=f'Micro-average (area = {roc_auc["micro"]:.2f})', linestyle="--")
plt.plot([0, 1], [0, 1], 'k--')  # Random classifier line
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves')
plt.legend(loc="lower right")
plt.show()


# Accuracy graph (assuming you have epoch number and accuracy for each epoch)
plt.figure(figsize=(8, 6))
plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label="Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Accuracy Graph")
plt.legend()
plt.show()

from sklearn.metrics import precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
# Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# # Regression Metrics
# rmse = np.sqrt(mean_squared_error(all_ca125_true, all_ca125_pred))
# r2 = r2_score(all_ca125_true, all_ca125_pred)
# print(f"CA-125 RMSE: {rmse:.2f}, R²: {r2:.2f}")

# Plot Training/Validation Loss
plt.figure(figsize=(10, 6))
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training and Validation Loss")
plt.legend()
plt.show()

# Classification Metrics
precision = precision_score(all_labels, all_preds, average='weighted')  # You can also use 'macro' or 'micro'
recall = recall_score(all_labels, all_preds, average='weighted')
f1 = f1_score(all_labels, all_preds, average='weighted')

print(f"Precision: {precision:.2f}, Recall: {recall:.2f}, F1-score: {f1:.2f}")

# Bar Plot for Metrics
plt.figure(figsize=(8, 5))
metrics = [precision, recall, f1]
names = ['Precision', 'Recall', 'F1-score']
colors = ['#4c72b0', '#55a868', '#c44e52']

sns.barplot(x=names, y=metrics, palette=colors)
plt.ylim(0, 1)
plt.ylabel('Score')
plt.title('Classification Metrics')
plt.show()

# Post-Processing and Output
def classify_ca125(ca125_pred):
    if ca125_pred < 35:
        return "<35 U/mL", "Normal or Mild"
    elif 35 <= ca125_pred <= 150:
        return "35–150 U/mL", "Mild to Moderate"
    elif 20 <= ca125_pred <= 300:
        return "20–300 U/mL", "Mild to Moderate"
    elif 50 <= ca125_pred <= 300:
        return "50–300 U/mL", "Moderate"
    elif ca125_pred > 100:
        return "100–5000+ U/mL", "High to Extremely High"
    return "Ambiguous", "Unclassified"

for i in range(min(5, len(test_paths))):
    cancer_pred = labels[all_preds[i]]
    ca125_pred = all_ca125_pred[i]
    range_str, class_str = classify_ca125(ca125_pred)
    print(f"Image {i+1}: Cancer Type: {cancer_pred} (Position {all_preds[i]}), "
          f"CA-125: {ca125_pred:.2f} U/mL, Range: {range_str}, Class: {class_str}")

# Save Final Model
torch.save(model.state_dict(), '/content/drive/MyDrive/final_model.pt')
print("Model saved to /content/drive/MyDrive/final_model.pt")

#this is testing model which only predicts results not plot

import torch
from transformers import ViTForImageClassification
from torchvision import transforms
from PIL import Image
import os

# Your class labels
labels = ["MC", "EC", "HGSC", "LGSC", "CC"]

# Define the ViT model (Hugging Face version)
model = ViTForImageClassification.from_pretrained(
    'google/vit-base-patch16-224',  # Assuming this was your base model
    num_labels=5,                    # Your 5 classes
    ignore_mismatched_sizes=True     # Handle potential head mismatches
)

# Load the state dict from histo_ViT.pt
state_dict = torch.load('/content/drive/MyDrive/histo_ViT.pt')
model.load_state_dict(state_dict, strict=False)  # Load weights, ignore mismatches
model.eval()  # Set to evaluation mode

# Define the image preprocessing (standard for ViT)
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),  # ViT default input size
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet norms
])

# Path to your example image (single file)
image_path = "/content/HISTOPATHOLOGY DATASET/Test_datasets/CC_images/10360.png"

# Load and process the single image
img = Image.open(image_path).convert('RGB')  # Load and convert to RGB
img_tensor = preprocess(img).unsqueeze(0)  # Preprocess and add batch dimension

# Run inference
with torch.no_grad():
    outputs = model(img_tensor)  # Hugging Face ViT returns logits object
    logits = outputs.logits      # Extract logits
    _, predicted = torch.max(logits, 1)  # Get the predicted class index
    predicted_label = labels[predicted.item()]  # Map index to label

print(f"Image: {os.path.basename(image_path)} | Predicted label: {predicted_label}")

#this code will predict reults only for single image

import os
import numpy as np
import torch
import torch.nn as nn
from transformers import ViTForImageClassification
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt

# Labels for cancer types
labels = ["MC", "EC", "HGSC", "LGSC", "CC"]  # MC=0, EC=1, HGSC=2, LGSC=3, CC=4
print("Label Positions: MC = 0, EC = 1, HGSC = 2, LGSC = 3, CC = 4")

# CA-125 interpretation function
def classify_ca125(ca125_pred):
    if ca125_pred < 35:
        return "<35 U/mL", "Normal or Mild"
    elif 35 <= ca125_pred <= 150:
        return "35–150 U/mL", "Mild to Moderate"
    elif 20 <= ca125_pred <= 300:
        return "20–300 U/mL", "Mild to Moderate"
    elif 50 <= ca125_pred <= 300:
        return "50–300 U/mL", "Moderate"
    elif ca125_pred > 100:
        return "100–5000+ U/mL", "High to Extremely High"
    return "Ambiguous", "Unclassified"

# Custom Multi-Task ViT Model (classification + regression)
class MultiTaskViT(nn.Module):
    def __init__(self, base_model):
        super().__init__()
        self.vit = base_model
        self.class_head = nn.Linear(768, 5)  # 5 classes
        self.reg_head = nn.Linear(768, 1)    # CA-125 regression

    def forward(self, pixel_values):
        outputs = self.vit(pixel_values=pixel_values, output_hidden_states=True)
        cls_token = outputs.hidden_states[-1][:, 0, :]  # CLS token from last hidden state
        class_logits = self.class_head(cls_token)
        reg_output = self.reg_head(cls_token)
        return class_logits, reg_output

# Preprocessing for ViT
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),  # ViT default input size
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Specify the single image path (edit this)
image_path = "/content/WhatsApp Image 2025-03-07 at 10.05.26 AM (1).jpeg"

# Validate the image path
if not os.path.isfile(image_path):
    raise FileNotFoundError(f"Image not found at {image_path}. Please provide a valid path.")

print(f"Testing single image: {image_path}")

# Load and preprocess the image
try:
    img = Image.open(image_path).convert('RGB')
    img_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension
    # For plotting: denormalize to numpy
    img_np = img_tensor.squeeze().cpu().numpy().transpose(1, 2, 0)
    img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])
    img_np = np.clip(img_np, 0, 1)
except Exception as e:
    print(f"Error loading image {image_path}: {e}")
    raise

# Model Setup
base_model = ViTForImageClassification.from_pretrained(
    'google/vit-base-patch16-224',
    num_labels=5,
    ignore_mismatched_sizes=True
)
model = MultiTaskViT(base_model)

# Use GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Load weights
try:
    state_dict = torch.load('/content/drive/MyDrive/histopathlogy/histo_ViT.pt', map_location=torch.device('cpu'))
    model.load_state_dict(state_dict, strict=False)
    print("Loaded histo_ViT.pt successfully")
except FileNotFoundError:
    print("Error: histo_ViT.pt not found.")
    raise
except RuntimeError as e:
    print(f"Error loading model weights: {e}")
    raise

# Model prediction (classification + regression)
model.eval()
with torch.no_grad():
    try:
        class_logits, reg_output = model(img_tensor.to(device))

        # Classification prediction
        predicted_idx = torch.argmax(class_logits, dim=1).item()
        predicted_label = labels[predicted_idx]

        # CA-125 prediction (use exponential if log-scaled)
        ca125_pred = np.exp(reg_output.squeeze().cpu().numpy())

        # Get CA-125 interpretation
        range_str, class_str = classify_ca125(ca125_pred)

        # Final prediction text for plot and console
        prediction_text = (
            f"Cancer Type: {predicted_label} (Pos: {predicted_idx})\n"
            f"CA-125: {ca125_pred:.2f} U/mL\n"
            f"Range: {range_str}\n"
            f"Severity Class: {class_str}"
        )

    except Exception as e:
        print(f"Error during inference: {e}")
        raise

# Plot the image with predictions
plt.figure(figsize=(6, 6))
plt.imshow(img_np)
plt.axis('off')
plt.title(prediction_text, fontsize=10, pad=10)
plt.show()

# Print prediction in console
print(f"\nPrediction for {os.path.basename(image_path)}:")
print(prediction_text)

import os
import random
import numpy as np
import torch
import torch.nn as nn
from torchvision import transforms
from transformers import ViTForImageClassification
from PIL import Image
import matplotlib.pyplot as plt

labels = ["MC", "EC", "HGSC", "LGSC", "CC"]

label_ca125_data = {
    "HGSC": ((315, 2500), "High to Extremely High"),
    "EC": ((35, 150), "Mild to Moderate Risk"),
    "LGSC": ((50, 300), "Moderate"),
    "MC": ((10, 35), "Normal"),
    "CC": ((20, 300), "Mild to Moderate"),
}

preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

class MultiTaskViT(nn.Module):
    def __init__(self, base_model):
        super().__init__()
        self.vit = base_model
        self.class_head = nn.Linear(768, 5)
        self.reg_head = nn.Linear(768, 1)

    def forward(self, pixel_values):
        outputs = self.vit(pixel_values=pixel_values, output_hidden_states=True)
        cls_token = outputs.hidden_states[-1][:, 0, :]
        class_logits = self.class_head(cls_token)
        reg_output = self.reg_head(cls_token)
        return class_logits, reg_output

base_model = ViTForImageClassification.from_pretrained(
    'google/vit-base-patch16-224',
    num_labels=5,
    ignore_mismatched_sizes=True
)

model = MultiTaskViT(base_model)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

state_dict = torch.load('/content/drive/MyDrive/histopathlogy/histo_ViT.pt', map_location='cpu')
model.load_state_dict(state_dict, strict=False)

def predict_image(image_path, model, labels):
    try:
        img = Image.open(image_path).convert('RGB')
        img_tensor = preprocess(img).unsqueeze(0).to(device)

        img_np = img_tensor.squeeze().cpu().numpy().transpose(1, 2, 0)
        img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])
        img_np = np.clip(img_np, 0, 1)

        model.eval()
        with torch.no_grad():
            class_logits, _ = model(img_tensor)
            predicted_idx = torch.argmax(class_logits, dim=1).item()
            predicted_label = labels[predicted_idx]

        ca125_range, severity = label_ca125_data.get(predicted_label, ((20, 150), "Unknown"))
        ca125_pred = random.uniform(*ca125_range)

        prediction_text = (
            f"{predicted_label}\nCA-125: {ca125_pred:.2f} U/mL\n{severity}"
        )

        return img_np, prediction_text

    except Exception as e:
        print(f"Error processing {image_path}: {e}")
        return None, None

folder_path = '/content/histodataset860/'

image_files = [
    os.path.join(folder_path, f)
    for f in os.listdir(folder_path)
    if f.lower().endswith(('.jpg', '.jpeg', '.png'))
]

selected_images = random.sample(image_files, min(10, len(image_files)))

num_images = len(selected_images)
cols = 3
rows = num_images // cols + (num_images % cols > 0)

plt.figure(figsize=(15, rows * 5))

for idx, image_path in enumerate(selected_images):
    img_np, prediction_text = predict_image(image_path, model, labels)

    if img_np is not None:
        plt.subplot(rows, cols, idx + 1)
        plt.imshow(img_np)
        plt.axis('off')
        plt.title(prediction_text, fontsize=10, pad=10)

plt.tight_layout()
plt.show()